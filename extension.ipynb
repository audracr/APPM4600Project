{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b5b90ce6-c5d3-40e8-ae62-53e4ff9dc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0ce2111f-f885-465d-bf5b-b65372322f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wdbc.data', header=None,sep=',')\n",
    "df = df.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fd760091-ca8c-4148-ae4a-e8ba43c97324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1].unique()\n",
    "df[1] = df[1].replace({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1e7c3ed7-416b-4497-91a1-cb710a4a19af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1      2      3       4       5        6        7       8        9   \\\n",
       "0   1  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "1   1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "2   1  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "3   1  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "4   1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "       10  ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.2419  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.1812  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.2069  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.2597  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.1809  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "77f7b0ee-d4d0-4bd7-91fa-28eaf1e873ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=1)\n",
    "y = df[1]\n",
    "\n",
    "#train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "#need to scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "99436991-14b7-4809-b495-0aa611d47ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_loss(w, X, y):\n",
    "    z = X @ w\n",
    "    return np.mean(np.log(1 + np.exp(-y * z)))\n",
    "\n",
    "def gradient(w, X, y):\n",
    "    z = X @ w\n",
    "    return -X.T @ (y * (1 - sigmoid(y * z))) / len(y)\n",
    "\n",
    "def line_search(f, x, p, nabla, X, y): \n",
    "    a = 1\n",
    "    c1 = 1e-4 \n",
    "    c2 = 0.9 \n",
    "    fx = f(x)\n",
    "    x_new = x + a * p \n",
    "    nabla_new = gradient(x_new, X, y)\n",
    "\n",
    "    while f(x_new) >= fx + (c1 * a * nabla.T @ p) or nabla_new.T @ p <= c2 * nabla.T @ p:\n",
    "        a *= 0.5\n",
    "        x_new = x + a * p \n",
    "        nabla_new = gradient(x_new, X, y)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9dff2e61-7d7e-4fc9-ab9c-ef356e260cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs(X, y, epsilon=1e-5, max_iter=100):\n",
    "    n_features = X.shape[1]\n",
    "    w = np.zeros(n_features)\n",
    "    H = np.eye(n_features)\n",
    "    k = 0\n",
    "\n",
    "    grad = gradient(w, X, y)\n",
    "\n",
    "    while np.linalg.norm(grad) > epsilon and k < max_iter:\n",
    "        p = -H @ grad\n",
    "\n",
    "        alpha = line_search(\n",
    "            lambda w_: logistic_loss(w_, X, y),\n",
    "            w,p,grad,X,y)\n",
    "\n",
    "        w_new = w + alpha * p\n",
    "\n",
    "        s = w_new - w\n",
    "        grad_new = gradient(w_new, X, y)\n",
    "        yk = grad_new - grad\n",
    "        rho = 1.0 / (yk @ s)\n",
    "\n",
    "        I = np.eye(n_features)\n",
    "        H = (I - rho * np.outer(s, yk)) @ H @ (I - rho * np.outer(yk, s)) + rho * np.outer(s, s)\n",
    "\n",
    "        w = w_new\n",
    "        grad = grad_new\n",
    "        k += 1\n",
    "\n",
    "    return w, k, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a73fa7ab-2f8c-4a8a-b69c-7a029f1dd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_bfgs(X, y, epsilon=1e-5, max_iter=100, m=10):\n",
    "    n_features = X.shape[1]\n",
    "    w = np.zeros(n_features)\n",
    "    k = 0\n",
    "\n",
    "    grad = gradient(w, X, y)\n",
    "    history = []\n",
    "\n",
    "    while np.linalg.norm(grad) > epsilon and k < max_iter:\n",
    "        # 2 loop recursion\n",
    "        q = grad.copy()\n",
    "        alphas = []\n",
    "        rhos = []\n",
    "\n",
    "        for s_i, y_i in reversed(history):\n",
    "            rho_i = 1.0 / (y_i @ s_i)\n",
    "            rhos.append(rho_i)\n",
    "            alpha_i = rho_i * (s_i @ q)\n",
    "            alphas.append(alpha_i)\n",
    "            q = q - alpha_i * y_i\n",
    "\n",
    "        r = q\n",
    "\n",
    "        for i, (s_i, y_i) in enumerate(history):\n",
    "            rho_i = rhos[-(i+1)]\n",
    "            beta = rho_i * (y_i @ r)\n",
    "            r = r + s_i * (alphas[-(i+1)] - beta)\n",
    "\n",
    "        p = -r\n",
    "\n",
    "        alpha = line_search(\n",
    "            lambda w_: logistic_loss(w_, X, y),\n",
    "            w,p,grad,X,y)\n",
    "\n",
    "        w_new = w + alpha * p\n",
    "\n",
    "        s = w_new - w\n",
    "        grad_new = gradient(w_new, X, y)\n",
    "        yk = grad_new - grad\n",
    "\n",
    "        # want m pairs\n",
    "        if len(history) == m:\n",
    "            history.pop(0)\n",
    "        history.append((s, yk))\n",
    "\n",
    "        w = w_new\n",
    "        grad = grad_new\n",
    "        k += 1\n",
    "\n",
    "    return w, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e21f3f7f-986e-4cac-8c29-1e299974eb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8859649122807017\n",
      "BFGS converged in 58 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/gf88wpr14f1gdnf2fk83dbrr0000gn/T/ipykernel_1769/1074106401.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "w_final, k_final, H_final = bfgs(X_train, y_train)\n",
    "\n",
    "y_pred_prob = sigmoid(X_test @ w_final)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(f\"BFGS converged in {k_final} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c53abe01-2b91-4691-9dbe-1a581a1940a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8771929824561403\n",
      "L-BFGS converged in 59 iterations\n"
     ]
    }
   ],
   "source": [
    "w_final, k_final = l_bfgs(X_train, y_train,m=15)\n",
    "\n",
    "y_pred_prob = sigmoid(X_test @ w_final)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(f\"L-BFGS converged in {k_final} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cc0dd-db97-4592-ac34-6e54c31c389c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
